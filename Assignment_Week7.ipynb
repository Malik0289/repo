{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# IS362 Week 7 Assignment\n# Ahmad Malik, 10/09/2022",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's start by importing the things we will need and the .csv file we will be using. We will create and work on a copy as always.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nratings = pd.read_csv(\"C:/Users/amalik/Desktop/ratings.csv\")\nratings_copy = ratings.copy()\nratings_copy",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's get the mean for each person and for each movie, disregarding the NaN values and add it as a row and a column. Lane and Caroline have watched all the movies.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ratings_copy.loc['mean'] = ratings_copy.mean()\nratings_copy['mean'] = ratings_copy.mean(axis=1)\nratings_copy",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Looks like the Maze Runner 3 movie had the highest overall rating, and Lisa was the happiest person to rate movies highly. Next, let's normalize the data and get the stats. We'll work on another copy.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "normd = ratings.copy()\nto_norm = ['Black Panther', 'Tomb Raider', 'Maze Runner 3', 'Godzilla', 'Step Sisters', 'Dunkirk']\nnormalized = normd[to_norm] = normd[to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\nnormalized",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "ratings_normalized = ratings.copy()\ncols = list(ratings_normalized)\ncols.pop(0) #pops off \"Untitled\"\n#print (cols)\nr_nrmd = ratings_normalized[cols] = ratings_normalized[cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\nr_nrmd",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "r_nrmd.loc['mean'] = r_nrmd.mean()\nr_nrmd['mean'] = r_nrmd.mean(axis = 1)\nr_nrmd",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Some of the advantages that might occur with using normalized data are that there'll be less drastic results appearing, and they'll be easier to graph. This itself can also be a disadvantage because where there are big differences, they'll look small. Another reason as to why normalizing data is a good idea is that if there are different ways of rating films, scoring whatever it is that you're scoring - eg: 1-5 vs 1-10 vs 1-100, normalization will allow us to take a look at all of them without skewing the graphs that we draw.",
      "metadata": {}
    }
  ]
}